{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Transforming, Grouping & Sorting Data**\n",
        "Using functions such as `map()` and `apply()` enable us to transform our data. These functions return a transformed data without modifying the original data.  \n",
        "\n",
        "### **Learning outcome:**\n",
        "- To learn how to transform our data (series or dataframe) using `map()` and `apply()` for mapping values\n",
        "- Use lambda for column and row operations when we use mapping function.\n",
        "- Introduce methods to aggregate data points using `groupby()` and working with Multiindex"
      ],
      "metadata": {
        "id": "YtCq8c1a57q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data transformation.\n",
        "To map our data, is to use a function that enables us to take one set of values and \"map\" them to another set of values. Why would one do this? In data science, we often have to create a new representation from the exisiting data, or we need to transform our data from the current format to a different format to do downstream analysis. In this notebook we will introduce two mapping methods; `map()` and `apply()`\n",
        "\n",
        "&nbsp;\n",
        "####  **Crime Rates Dataset**\n",
        "We will continue to use the crime rate dataset from M2_CL5"
      ],
      "metadata": {
        "id": "KIgN2vyt7JTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = \"{:,.2f}\".format"
      ],
      "metadata": {
        "id": "GUy9kA6t9RKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read in data set and converting it to a pandas dataframe\n",
        "crime_rates = pd.read_csv('https://raw.githubusercontent.com/csbfx/advpy122-data/master/crime_rates.csv',\n",
        "                          names=['state', 'year', 'pop', 'violent', 'murder', 'rape', 'robbery', 'assault', 'property', 'burglary', 'larceny','vehicle'],\n",
        "                          header=0\n",
        "                          )\n",
        "\n",
        "## A reminder of what columns are in this dataset and the size of the dataframe\n",
        "crime_rates.info()"
      ],
      "metadata": {
        "id": "oP4vgb5t9zcc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## To show the statistic of our int columns\n",
        "crime_rates.describe()"
      ],
      "metadata": {
        "id": "gwkkgBfxXHIK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Axb1MWR5HAr"
      },
      "source": [
        "##  Dropping columns with `drop()`\n",
        "This data set as we previously observed is clean and does not have redundant data. For practice, we will assume that we do not need the column \"year\" or \"pop\".  Pandas DataFrame method `drop()` will return a new DataFrame by default but it will not overwrite the current DataFrame. If you want to overwrite the current DataFrame, you can set the argument `inplace=True`.  \n",
        "\n",
        "&nbsp;\n",
        "The drop() method can drop either rows or columns. The default is rows (`axis=0`). To drop columns, set the argument to `axis=1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jH7R3B05HAr"
      },
      "source": [
        "crime_rates_dropped = crime_rates.drop(['year','pop'], axis=1)\n",
        "crime_rates_dropped.head()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `map()` ##\n",
        "The Series method [`map()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html) maps values of Series according to an input function and returns a new Series.   \n",
        "\n",
        "> `new_series = a_series.map(some_function)`\n",
        "\n",
        "**Scenario**: Suppose that we wanted to redefine states to broad region using a mapping function.\n",
        "\n",
        "We will be using a <i>**lambda function**</i> in the example below. You can review Python lambda function [here](https://www.w3schools.com/python/python_lambda.asp)."
      ],
      "metadata": {
        "id": "HdfQlLVdMD8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Genre': ['Action', 'Comedy', 'Drama', 'Horror']})\n",
        "genre_map = {'Action':'A', 'Comedy':'C', 'Drama':'D', 'Horror':'H'}\n",
        "\n",
        "### map()\n",
        "df['S_Genre'] = df['Genre'].map(genre_map)\n",
        "\n",
        "### apply() on a series\n",
        "df['Uppercase_Genre'] = df['Genre'].apply(lambda x: x.upper())\n",
        "df"
      ],
      "metadata": {
        "id": "1JmKRVOhM_lK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Example function that adds 5 to argument passed in\n",
        "def fxn_add5(x):\n",
        "    return x+5\n",
        "print(fxn_add5(10))\n",
        "\n",
        "## Rewrite the function above as a lambda function\n",
        "## lambda arg: expression\n",
        "arg_add5 = lambda x: x+5\n",
        "list(map(arg_add5, [10, 9, 8]))# Using map to apply the lambda function to each element of the list"
      ],
      "metadata": {
        "id": "VD2JSUzzN7_5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOAtqr5W5HAr"
      },
      "source": [
        "###  Mapping values with `map()`\n",
        "Here we will map states to broad regions using a mapping function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU-2jMcs5HAs"
      },
      "source": [
        "## Use a dictionary to define the regions\n",
        "region_map = {\n",
        "    'California': 'West',\n",
        "    'Washington': 'West',\n",
        "    'New York': 'Northeast',\n",
        "    'Illinois': 'Midwest',\n",
        "    'Colorado': 'Midwest',\n",
        "    'Alabama': 'South',\n",
        "    'Arkansas': 'South',\n",
        "    'Arizona': 'South',\n",
        "    'Texas': 'South',\n",
        "    'Georgia': 'South',\n",
        "    'Florida': 'South'\n",
        "}\n",
        "crime_rates['Region'] = crime_rates['state'].map(lambda x: region_map.get(x, 'Other'))\n",
        "crime_rates[['state','Region']].drop_duplicates().head() #This does not overwrite the DataFrame"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function you pass to `map()` should expect a single value from the Series (a point value, in the above example), and return a transformed version of that value. `map()` returns a new Series where all the values have been transformed by your function."
      ],
      "metadata": {
        "id": "J2IbhgpsSK69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new column called 'pop-scale', which stores the values we define the scale of a population depending on the size of the population. We know from using\n",
        "> crime_rates.describe()  \n",
        "\n",
        "that the population ranges from 226,167.00 to 35,484,453.00\n",
        "-  \\> 20,000,001.00 - 3 (large population)\n",
        "-  between 1,000,001.00 and 20,000,000.00 - 2 (midsize population)\n",
        "-  below 1,000,000.00 - 1 (small population)"
      ],
      "metadata": {
        "id": "_q3Qs43NShNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create function to do transformation for map()\n",
        "# Since we are only looking at population(a single column), we do not need to use apply()\n",
        "\n",
        "def pop_scale(x): # x is going to be a value from the Series\n",
        "    if x > 20000001:\n",
        "        return 3\n",
        "    elif 1000001 < x <= 20000000:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "scale = crime_rates['pop'].map(pop_scale) # should return a Series that contains the star values\n",
        "crime_rates['pop_scale'] = scale # Add a new column scale to the DataFrame wine\n",
        "crime_rates.head()"
      ],
      "metadata": {
        "id": "e_VxZsKwT6BL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyHy4nfU5HAs"
      },
      "source": [
        "##  Applying transformations with `apply()`\n",
        "The DataFrame method, [`apply()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html), should be used if we want to <u>transform the whole DataFrame</u> by calling a custom method on each row. We can use `apply()` to pass a function and apply it on every single value of the panda series.  \n",
        "\n",
        "Below we will call `crime_rates.apply()` with `axis='columns'`. If we use `axis='index'`, then instead of passing a function to transform each row for the column(s), we would need to provide a function to transform each column for the row(s).\n",
        "\n",
        "Recall:  \n",
        "- **Single column:** similar to `.map()`.\n",
        "- **Row-wise operations:** use `axis='columns'` or `axis=1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sALf5Gqd5HAs"
      },
      "source": [
        "## We are going to define if a Crime level is consider \"high\" based on the rate of violent crimes\n",
        "crime_rates['crime_level'] = crime_rates['violent'].apply(\n",
        "    lambda x: 'High' if x > 1000 else ('Med' if 999 > x > 500 else 'Low')\n",
        ")\n",
        "crime_rates[['violent','crime_level']].head()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIT6eMt75HAs"
      },
      "source": [
        "## Combine multiple types of crime to get the total crime rate\n",
        "crime_rates['total_crime'] = crime_rates.apply(\n",
        "    lambda row: row['violent'] + row['murder'] + row['assault'],\n",
        "    axis='columns'\n",
        ")\n",
        "crime_rates[['violent','murder', 'assault', 'total_crime']].head()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we are performing an operation between a lot of values, pandas looks at the expression and figures out that we must mean to do the mathematical expression on in the dataset.\n",
        "\n",
        "Pandas will also understand what to do if we perform these operations between Series of equal length. For example, we combine the values of different crime type in the dataset. You can also combine strings, but you can not combine int and string values.\n",
        "\n",
        "**Note:**\n",
        "`map()` and `apply()` **return new, transformed Series and DataFrames, respectively**. They <i>**don't modify**</i> the original data they're called on."
      ],
      "metadata": {
        "id": "sWcwMZWEY79R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Groupwise analysis\n",
        "Any time we see a question involving the words ”how many ... for each ...” the answer is `value_counts`. We can replicate what `value_counts()` does by doing the following:"
      ],
      "metadata": {
        "id": "45oaqECeaDXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How many states have the high level of crime?\n",
        "crime_rates.groupby('crime_level').state.count()"
      ],
      "metadata": {
        "id": "tRkAqHopaPZH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crime_rates['crime_level'].value_counts()"
      ],
      "metadata": {
        "id": "oU0CE0fQatTM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) created different category of crime level based on the number of violet crime rates to a given state. For each of these groups, we grabbed the `crime_level()` column and counted how many times it appeared. value_counts() is just a shortcut to this `groupby()` operation.\n",
        "\n",
        "We can use any of the summary functions with this data. For example, to get the lowest violent crime rate for each year, we can do the following:"
      ],
      "metadata": {
        "id": "1p4eZ_J4bDMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crime_rates.groupby('year').violent.min().head()"
      ],
      "metadata": {
        "id": "mTQ7xkTIcC-R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## To get the state that is associated with the groupby, we can reference the index\n",
        "min_violent_by_year_index = crime_rates.groupby('year')['violent'].idxmin()\n",
        "\n",
        "## Use .loc to pull out the rows that contain the index of interest\n",
        "state_with_min_violent = crime_rates.loc[min_violent_by_year_index, ['year', 'state', 'violent']]\n",
        "state_with_min_violent.head()"
      ],
      "metadata": {
        "id": "RyXedGyHeSMG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can think of each group we generate as being a slice of our DataFrame containing only data with values that match. This DataFrame is accessible to us directly using the `apply()` method, and we can then manipulate the data in any way we see fit."
      ],
      "metadata": {
        "id": "esGbJEX8db7x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsoDFtNR5HAt"
      },
      "source": [
        "##  Aggregation with `groupby()`\n",
        "Another `groupby()` method worth mentioning is `agg()`, which lets you run a bunch of different functions on your DataFrame simultaneously. For example, we can generate a simple statistical summary of the dataset as follows:\n",
        "\n",
        "We will group by `year`, and compute mean values for the different crime types across the states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTlxQV0q5HAt"
      },
      "source": [
        "grouped = crime_rates.groupby(['year'])[['violent','murder', 'assault']].mean()\n",
        "grouped.head()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIc-t8EU5HAt"
      },
      "source": [
        "## Multi-Index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In all of the examples we've seen thus far we've been working with DataFrame or Series objects with a single-label index. `groupby()` is slightly different in the fact that, depending on the operation we run, it will sometimes result in what is called a multi-index.\n",
        "\n",
        "A multi-index differs from a regular index in that it has multiple levels. Multi-indices have several methods for dealing with their tiered structure which are absent for single-level indices. They also require two levels of labels to retrieve a value. Dealing with multi-index output is a common \"gotcha\" for users new to pandas.\n",
        "\n",
        "The use cases for a multi-index are detailed alongside instructions on using them in the [MultiIndex / Advanced Selection](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) section of the pandas documentation.\n",
        "\n",
        "However, in general the multi-index method you will use most often is the one for converting back to a regular index, the `reset_index()` method:"
      ],
      "metadata": {
        "id": "vHxVHOLcgc7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_flat = grouped.reset_index()\n",
        "grouped_flat.head()"
      ],
      "metadata": {
        "id": "Ydt7yTY4gynM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting\n",
        "Looking again at `state_with_min_violent` we can see that grouping returns data in index order, not in value order. That is to say, when outputting the result of a `groupby`, the order of the rows is dependent on the values in the index, not in the data.\n",
        "\n",
        "To get data in the order want it in we can sort it ourselves. The `sort_values()` method is handy for this. [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) defaults to an ascending sort, where the lowest values go first. However, most of the time we want a descending sort, where the higher numbers go first."
      ],
      "metadata": {
        "id": "mPLk3LDlhBUx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYU1Ye0P5HAt"
      },
      "source": [
        "##  Sorting with `sort_values()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ALUQFZ5HAt"
      },
      "source": [
        "sorted_df = state_with_min_violent.sort_values(\n",
        "    by=['year','state', 'violent'],\n",
        "    ascending=[True, False, False]\n",
        ")\n",
        "sorted_df.head()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJZ1YA9C5HAt"
      },
      "source": [
        "##  Class Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Exercise CL6.1\n",
        "Identify the top three states per year by \"property\" crime rates."
      ],
      "metadata": {
        "id": "8NElMIyQjqH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Exercise CL6.2\n",
        "**Normalize Violent Crime Rate**\n",
        "\n",
        "Compute a new column, violent_rate_per_100k, that represents violent incidents per 100,000 people:\n",
        "\n",
        "violent_rate_per_100k = violent / pop * 100000\n",
        "\n",
        "Use `apply()` either column-wise or row-wise to perform the calculation."
      ],
      "metadata": {
        "id": "GA_It55hiCk7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYfZ5i2s5HAt"
      },
      "source": [
        "### Class Exercise CL6.3\n",
        "**Understanding total crime rates**  \n",
        "Group by `year` and `state`, sum the rate of `violent`, `property`, `burgalry`, `larceny`, `vehicle` crimes into `crime_total`. Sort the DataFrame by `year` and `crime_total`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Exercise CL6.4\n",
        "**Crime Change by State year over year**  \n",
        "Use `groupby()` and `shift()` to compute the percentage change in violent crime compared to the previous year for each state. You will want to group by state and sort_values() to display your data chronologically.  \n",
        "note: `shift()` removes the first element from the array and returns that removed element."
      ],
      "metadata": {
        "id": "Vnp5wxTFihj6"
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}